{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feel like Alessandro is gonna hate on me for using a jupyter but"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ast\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from storage import Storage\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.db\n",
      "c:\\Users\\20221737\\Documents\\Honors AI\\spoticolor-main\\spoticolor\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "storage = Storage()\n",
    "device\n",
    "\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# store = storage.Storage()\n",
    "validTracks = storage.getValidTracks()\n",
    "print(validTracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_data = []\n",
    "\n",
    "for track_id, track_data in validTracks:\n",
    "    try:\n",
    "       decoded_data = json.loads(track_data)\n",
    "       tracks_data.append((track_id, decoded_data))\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error processing data for track_id: {track_id}. Data: {track_data}\")\n",
    "\n",
    "print(tracks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tracks_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tracks_data[0][1]['segments'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broken track\n",
    "store.getTrack('05wb6MEyJeG2z1MVCIXxC8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['start', 'duration', 'confidence', 'loudness_start', 'loudness_max', 'loudness_max_time', 'loudness_end', 'pitches', 'timbre']\n",
    "\n",
    "scalers = {feature: MinMaxScaler() for feature in ['start', 'duration', 'confidence', 'loudness_start']}\n",
    "# Feel like min max is worse for loudenss but idk we have to test it ig\n",
    "scalers.update({feature: StandardScaler() for feature in ['loudness_start', 'loudness_max', 'loudness_end']})\n",
    "\n",
    "for feature in features:\n",
    "    all_values = np.array([seg[feature] for _, track_data in tracks_data for seg in track_data['segments']]).reshape(-1, 1)\n",
    "    scalers[feature].fit(all_values)\n",
    "    \n",
    "    for _, track_data in tracks_data:\n",
    "        for seg in track_data['segments']:\n",
    "            seg[feature] = scalers[feature].transform([[seg[feature]]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_data[0][1]['segments'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_segments(segments):\n",
    "    flattened_segments = [np.array([\n",
    "        seg['start'], seg['duration'], seg['confidence'], seg['loudness_start'], \n",
    "        seg['loudness_max_time'], seg['loudness_max'], seg['loudness_end']\n",
    "    ] + seg['pitches'] + seg['timbre']) for seg in segments]\n",
    "    \n",
    "    return np.array(flattened_segments)\n",
    "\n",
    "def pad_tracks(tracks, max_segments, segment_size=31):\n",
    "    padded_tracks = np.zeros((len(tracks), max_segments, segment_size))\n",
    "    \n",
    "    for i, (_, track_data) in enumerate(tracks):\n",
    "        flattened_segments = flatten_segments(track_data['segments'])\n",
    "        num_segments = len(flattened_segments)\n",
    "        padded_tracks[i, :num_segments, :] = flattened_segments[:max_segments]\n",
    "    \n",
    "    return padded_tracks\n",
    "\n",
    "max_segments = max(len(track_data['segments']) for _, track_data in tracks_data)\n",
    "\n",
    "padded_tracks = pad_tracks(tracks_data, max_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tracks.shape # (n_tracks, n_segments, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddedTracks_train, paddedTracks_test = train_test_split(padded_tracks, test_size=0.2, random_state=42)\n",
    "\n",
    "tracksTensor_train = torch.tensor(paddedTracks_train, dtype=torch.float32).to(device)\n",
    "trainDataset = TensorDataset(tracksTensor_train)\n",
    "trainDataloader = DataLoader(trainDataset, batch_size=32, shuffle=True)\n",
    "\n",
    "tracksTensor_test = torch.tensor(paddedTracks_test, dtype=torch.float32).to(device)\n",
    "testDataset = TensorDataset(tracksTensor_test)\n",
    "testDataloader = DataLoader(testDataset, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim=31, encoding_dim=3):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(32, encoding_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return encoded, decoded\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dim=31, encoding_dim=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "\n",
    "    with tqdm(trainDataloader, unit=\"batch\", desc=f\"Epoch {epoch + 1}/{epochs}\") as tepoch:\n",
    "        for batch in tepoch:\n",
    "            inputs = batch[0].to(device)\n",
    "            inputs = inputs.view(-1, 31) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            _, decoded = model(inputs)\n",
    "            loss = criterion(decoded, inputs)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=(running_loss / (tepoch.n + 1)))\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / len(trainDataloader)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
